{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['HAVEN_DATABASE'] = 'haven'\n",
    "os.environ['AWS_PROFILE'] = 'admin'\n",
    "\n",
    "from mirrorverse.utils import read_data_w_cache\n",
    "from haven.db import write_data, drop_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "with elevation as (\n",
    "    select \n",
    "        h3_index,\n",
    "        elevation\n",
    "    from \n",
    "        mean_elevation_by_h3\n",
    "    where \n",
    "        h3_resolution = 4\n",
    "), physics as (\n",
    "    select \n",
    "        date,\n",
    "        h3_index,\n",
    "        temperature,\n",
    "        salinity\n",
    "    from \n",
    "        copernicus_physics\n",
    "    where \n",
    "        depth_bin = 25\n",
    "        and h3_resolution = 4\n",
    "        and region = 'chinook_study'\n",
    "), features as (\n",
    "    select \n",
    "        _individual, _decision, _choice, _selected, _train, tag_key,\n",
    "        mixed_layer_thickness, net_primary_production, \n",
    "        water_heading, movement_heading, \n",
    "        distance, origin_h3_index, next_h3_index, h3_index, time,\n",
    "        region, home_lat, home_lon, fork_length_cm,\n",
    "        cos_time, sin_time, date_format(time, '%Y-%m-%d') as date\n",
    "    from \n",
    "        movement_model_features_m3_a4\n",
    ")\n",
    "\n",
    "select \n",
    "    f.*,\n",
    "    e.elevation,\n",
    "    p.salinity,\n",
    "    p.temperature\n",
    "from \n",
    "    features f\n",
    "    inner join elevation e \n",
    "        on e.h3_index = f.next_h3_index\n",
    "    inner join physics p \n",
    "        on p.h3_index = f.next_h3_index \n",
    "        and p.date = f.date \n",
    "\"\"\"\n",
    "data = read_data_w_cache(\n",
    "    sql\n",
    ")\n",
    "print('Shape Before:', data.shape)\n",
    "\n",
    "# filter down to decisions where a movement happened\n",
    "# within a specific range\n",
    "_filter = data[\n",
    "    data['_selected'] & (data['distance'] < 50)\n",
    "][['_individual', '_decision']].drop_duplicates()\n",
    "data = data.merge(_filter, how='inner')\n",
    "\n",
    "data['stay_put'] = (data['distance'] == 0).astype(int).astype(float)\n",
    "\n",
    "# remove the choices where the distance is outside of the\n",
    "# range to be considered\n",
    "data = data[(data['distance'] < 50)]\n",
    "print('Shape After:', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in range(1000, 4000, 1000):\n",
    "    for _individual in data[data['_train']]['_individual'].unique():\n",
    "        df = data[data['_individual'] == _individual]\n",
    "        df['_individual'] = i + _individual\n",
    "\n",
    "        size = df.shape[0]\n",
    "\n",
    "        # elevation\n",
    "        delta = 1.0 + np.random.uniform(low=-0.1, high=0.1, size=size)\n",
    "        df['elevation'] = df['elevation'] * delta\n",
    "\n",
    "        # salinity\n",
    "        delta = np.random.uniform(low=-0.25, high=0.25, size=size)\n",
    "        df['salinity'] = df['salinity'] + delta\n",
    "\n",
    "        # mixed layer thickness\n",
    "        delta = np.random.uniform(low=-5, high=5, size=size)\n",
    "        df['mixed_layer_thickness'] = df['mixed_layer_thickness'] + delta\n",
    "        df.loc[df['mixed_layer_thickness'] < 0, 'mixed_layer_thickness'] = 0\n",
    "\n",
    "        # movement heading\n",
    "        delta = np.random.uniform(low=-np.pi/8, high=np.pi/8, size=size)\n",
    "        df['movement_heading'] = (df['movement_heading'] + delta) % (2 * np.pi)\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "additions = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[data['_train']].shape)\n",
    "print(additions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, additions])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catch_region_map(tag_key):\n",
    "    for i, _id in enumerate(['172', '202', '159', '205', '210', '229', '142']):\n",
    "        if tag_key.startswith(_id):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "data['catch_region'] = data['tag_key'].apply(catch_region_map)\n",
    "print(data['catch_region'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['rounded_mlt'] = round(data['mixed_layer_thickness'] / 5)*5\n",
    "print(data['mixed_layer_thickness'].max())\n",
    "data['normed_log_mlt'] = np.log(data['mixed_layer_thickness'] + 0.01) / np.log(data['mixed_layer_thickness'].max() + 0.01)\n",
    "px.histogram(data['normed_log_mlt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['normed_log_npp'] = np.log(data['net_primary_production'] + 0.01) / np.log(data['net_primary_production'].max() + 0.01)\n",
    "px.histogram(data['normed_log_npp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_angle(d):\n",
    "    return round(d / (np.pi/4)) * (np.pi/4)\n",
    "data['sin_mh'] = np.sin(data['movement_heading'])\n",
    "data['cos_mh'] = np.cos(data['movement_heading'])\n",
    "data['sin_wh'] = np.sin(data['water_heading'])\n",
    "data['cos_wh'] = np.cos(data['water_heading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['rounded_distance'] = round(data['distance'] / 10) * 10\n",
    "data['binned_distance'] = (data['distance'] - data['distance'].mean()) / data['distance'].std()\n",
    "px.histogram(data['binned_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[~data['region'].isin(['SEAK', 'WA/OR', 'BC']), 'home_lat'] = \\\n",
    "    data[data['region'].isin(['SEAK', 'WA/OR', 'BC'])]['home_lat'].mean()\n",
    "data['normed_home_lat'] = (data['home_lat'] - data['home_lat'].min()) \\\n",
    "    / (data['home_lat'].max() - data['home_lat'].min())\n",
    "px.histogram(data['normed_home_lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[~data['region'].isin(['SEAK', 'WA/OR', 'BC']), 'home_lon'] = \\\n",
    "    data[data['region'].isin(['SEAK', 'WA/OR', 'BC'])]['home_lon'].mean()\n",
    "data['normed_home_lon'] = (data['home_lon'] - data['home_lon'].min()) \\\n",
    "    / (data['home_lon'].max() - data['home_lon'].min())\n",
    "px.histogram(data['normed_home_lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['region_unknown'] = (~data['region'].isin(['SEAK', 'WA/OR', 'BC'])).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['rounded_fl'] = round(data['fork_length_cm'] / 5) * 5\n",
    "data['normed_fl'] = (data['fork_length_cm'] - data['fork_length_cm'].min()) / (data['fork_length_cm'].max() - data['fork_length_cm'].min())\n",
    "px.histogram(data['normed_fl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['rounded_salinity'] = round(data['salinity'] / 0.5) * 0.5\n",
    "print(data['salinity'].mean())\n",
    "print(data['salinity'].std())\n",
    "data['normed_salinity'] = (data['salinity'] - data['salinity'].mean()) / data['salinity'].std()\n",
    "px.histogram(data['normed_salinity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['elevation'] > -np.e, 'elevation'] = -np.e \n",
    "data['normed_elevation'] = (np.log(-data['elevation'])) / (np.log(-data['elevation']).max())\n",
    "px.histogram(data['normed_elevation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['rounded_temp'] = round(data['temperature'] / 2) * 2 \n",
    "data['normed_temp'] = (data['temperature'] - data['temperature'].mean()) / data['temperature'].std()\n",
    "px.histogram(data['normed_temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_table('movement_model_features_m9_a2')\n",
    "write_data(\n",
    "    data, 'movement_model_features_m9_a2', ['tag_key']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('_individual')['_decision'].nunique().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('_individual')['_decision'].nunique().quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['_individual', '_decision'])['_choice'].nunique().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
