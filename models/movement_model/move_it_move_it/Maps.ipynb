{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import h3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from mirrorverse.utils import read_data_w_cache\n",
    "from mirrorverse.plotting import plot_h3_slider, plot_h3_animation\n",
    "\n",
    "os.environ['HAVEN_DATABASE'] = 'haven'\n",
    "os.environ['AWS_PROFILE'] = 'admin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(version):\n",
    "    train = read_data_w_cache(\n",
    "        f'select * from movement_model_inference_m3_a4_v{version}'\n",
    "    )\n",
    "    train.loc[train['_train'], 'case'] = 'train'\n",
    "    train.loc[~train['_train'], 'case'] = 'val'\n",
    "    #test = read_data_w_cache(\n",
    "    #    f'select * from movement_model_inference_m3_a3_v{version}_test'\n",
    "    #)\n",
    "    #test['case'] = 'test'\n",
    "    data = train#data = pd.concat([train, test])\n",
    "    data['log_prob'] = np.log(data['probability'])\n",
    "    data['version'] = str(version)\n",
    "    return data \n",
    "\n",
    "v5 = get_data(5)\n",
    "v6 = get_data(6)\n",
    "v7 = get_data(7)\n",
    "\n",
    "v0 = v5.copy()\n",
    "v0['probability'] = 1/19\n",
    "v0['log_prob'] = np.log(v0['probability'])\n",
    "v0['version'] = '0'\n",
    "v0['log_odds'] = np.nan \n",
    "v0['odds'] = np.nan \n",
    "\n",
    "data = pd.concat([v0, v5, v6, v7])\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines_dict = {}\n",
    "versions = list(data['version'].unique())\n",
    "for version in versions:\n",
    "    baselines_dict[version] = data[(data['version'] == version) & data['_selected']][\n",
    "        ['_train', '_individual', '_decision', 'origin_h3_index', 'next_h3_index', 'log_prob', 'time', 'distance', 'tag_key']\n",
    "    ]\n",
    "    baselines_dict[version] = baselines_dict[version].rename({'log_prob': f'log_prob_{version}'}, axis=1)\n",
    "baselines = baselines_dict[versions[0]]\n",
    "for version in versions[1:]:\n",
    "    baselines = baselines.merge(baselines_dict[version])\n",
    "for v1 in sorted(versions, reverse=True):\n",
    "    for v2 in versions:\n",
    "        if v1 > v2:\n",
    "            baselines[f'diff_{v1}-{v2}'] = baselines[f'log_prob_{v1}'] - baselines[f'log_prob_{v2}']\n",
    "baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines['origin_lat'] = baselines['origin_h3_index'].apply(lambda h: h3.h3_to_geo(h)[0])\n",
    "baselines['origin_lon'] = baselines['origin_h3_index'].apply(lambda h: h3.h3_to_geo(h)[1])\n",
    "baselines['next_lat'] = baselines['next_h3_index'].apply(lambda h: h3.h3_to_geo(h)[0])\n",
    "baselines['next_lon'] = baselines['next_h3_index'].apply(lambda h: h3.h3_to_geo(h)[1])\n",
    "\n",
    "baselines['x'] = baselines['origin_lon']\n",
    "baselines['y'] = baselines['origin_lat']\n",
    "baselines['u'] = baselines['next_lon'] - baselines['origin_lon']\n",
    "baselines['v'] = baselines['next_lat'] - baselines['origin_lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalize(vmin=-1.0, vmax=1.0)\n",
    "cmap = plt.cm.RdBu\n",
    "\n",
    "individuals_map = {\n",
    "    \"unalaska\": [56, 58, 104], #[0, 4, 56, 58, 101, 104, 107, 108], \n",
    "    \"chignik\": [21, 48, 95], #[19, 21, 48, 95],\n",
    "    \"nanwalek\": [32, 10, 13], #[10, 13, 32, 37, 92, 96, 103, 105, 109], #, #\n",
    "    \"kodiak\": [99, 60, 49], #[35, 49, 60, 99, 110],\n",
    "    \"yakutat\": [93, 102, 106], #[39, 93, 97, 102, 106],\n",
    "    \"sitka\": [75, 83, 86], # [75, 79, 83, 86]\n",
    "    \"ebs\": [98]\n",
    "}\n",
    "extents_map = {\n",
    "    \"chignik\": [-167, -153, 52, 58],\n",
    "    \"unalaska\": [-172, -150, 50, 58],\n",
    "    \"nanwalek\": [-155, -140, 55, 62],\n",
    "    \"kodiak\": [-155, -144, 57, 62],\n",
    "    \"yakutat\": [-148, -130, 52, 62],\n",
    "    \"sitka\": [-137, -130, 51, 58],\n",
    "}\n",
    "heights_map = {\n",
    "    \"chignik\": 2.7,\n",
    "    \"unalaska\": 2.3,\n",
    "    \"nanwalek\": 3,\n",
    "    \"kodiak\": 3,\n",
    "    \"yakutat\": 3.3, \n",
    "    \"sitka\": 4, \n",
    "}\n",
    "\n",
    "region = \"sitka\"\n",
    "individuals = individuals_map[region]\n",
    "extent = extents_map[region]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, heights_map[region]*len(individuals)), ncols=2, nrows=len(individuals), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "def setup(ax, extent):\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "\n",
    "def quiver(ax, df, col):\n",
    "    return ax.quiver(\n",
    "        df['x'], df['y'], df['u'], df['v'], df[col],\n",
    "        transform=ccrs.PlateCarree(), \n",
    "        cmap=cmap, norm=norm,  \n",
    "        width=0.005,\n",
    "        scale=9,\n",
    "        linestyle=[':']\n",
    "    )\n",
    "\n",
    "for i, individual in enumerate(individuals):\n",
    "    left = axes[i, 0]\n",
    "    right = axes[i, 1]\n",
    "    setup(left, extent)\n",
    "    setup(right, extent)\n",
    "\n",
    "    df = baselines[(baselines['_individual'] == individual) & (baselines['distance'] > 0)]\n",
    "    quiver_left = quiver(left, df, 'diff_6-5')\n",
    "    quiver_right = quiver(right, df, 'diff_7-6')\n",
    "\n",
    "    tag_key = df['tag_key'].values[0]\n",
    "    left.set_title(f'tag id: {tag_key}, {individual}')\n",
    "\n",
    "\n",
    "# Add colorbars for each column\n",
    "cbar_ax_left = fig.add_axes([0.12, 0.89, 0.35, 0.02])  # [left, bottom, width, height]\n",
    "cbar_ax_right = fig.add_axes([0.53, 0.89, 0.35, 0.02])\n",
    "\n",
    "cbar_left = fig.colorbar(quiver_left, cax=cbar_ax_left, orientation='horizontal')\n",
    "cbar_right = fig.colorbar(quiver_right, cax=cbar_ax_right, orientation='horizontal')\n",
    "\n",
    "cbar_left.set_label('Log Likelihood Change 1 - 2')\n",
    "cbar_right.set_label('Log Likelihood Change 2 - 3')\n",
    "\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "\n",
    "fig.suptitle(\"Changes to Log Likelihoods for Models 1 and 2\", fontsize=16, y=0.95)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_fish = data[data['_selected']].groupby(['_individual', 'tag_key', 'version', '_train'])['log_prob'].sum().reset_index()\n",
    "by_fish_dict = {}\n",
    "versions = list(by_fish['version'].unique())\n",
    "for version in versions:\n",
    "    by_fish_dict[version] = by_fish[by_fish['version'] == version]\n",
    "    by_fish_dict[version] = by_fish_dict[version].rename({'log_prob': f'log_prob_{version}'}, axis=1)\n",
    "    del by_fish_dict[version]['version']\n",
    "by_fish = by_fish_dict[versions[0]]\n",
    "for version in versions[1:]:\n",
    "    by_fish = by_fish.merge(by_fish_dict[version])\n",
    "for v1 in sorted(versions, reverse=True):\n",
    "    for v2 in versions:\n",
    "        if v1 > v2:\n",
    "            by_fish[f'diff_{v1}-{v2}'] = by_fish[f'log_prob_{v1}'] - by_fish[f'log_prob_{v2}']\n",
    "by_fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals_map = {\n",
    "    \"unalaska\": [0, 4, 56, 58, 101, 104, 107, 108], \n",
    "    \"chignik\": [19, 21, 48, 95],\n",
    "    \"nanwalek\": [8, 10, 13, 32, 37, 92, 96, 103, 105, 109, 91, 100], #, #\n",
    "    \"kodiak\": [35, 49, 60, 99, 110],\n",
    "    \"yakutat\": [39, 93, 97, 102, 106],\n",
    "    \"sitka\": [75, 79, 83, 86, 94],\n",
    "    \"ebs\": [98]\n",
    "}\n",
    "\n",
    "map_individuals = {}\n",
    "for region, individuals in individuals_map.items():\n",
    "    for individual in individuals:\n",
    "        map_individuals[individual] = region\n",
    "\n",
    "df = by_fish[~by_fish['_train']]\n",
    "df['region'] = df['_individual'].apply(lambda i: map_individuals[i])\n",
    "df = df.sort_values('region').reset_index(drop=True).reset_index()\n",
    "px.bar(\n",
    "    df, x='index', y='diff_7-5', color='region'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
