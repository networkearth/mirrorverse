\documentclass[11pt,a5paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[super]{nth}

\title{Perspectives on Stewardship}
\author{Marcel Gietzmann-Sanders}
\date{}
\setcounter{tocdepth}{1}
\begin{document}
\maketitle
\tableofcontents
\newpage

\section{What it Means to Manage}

"Taking a close look at what's around us, there is some sort of a harmony. It is the harmony of overwhelming and collective murder." - Werner Herzog on the Amazon rainforest, 1981. \newline

I absolutely love this quote. Not because I dislike rainforests or am a sadist but because it is illuminating an essential part of the natural world that we rarely think about. If I bring up rainforests, the arctic, or the oceans, to most people that is synonymous with beautiful butterflies enjoying the sunlight filtering down through a magnificent canopy, polar bear cubs playing in the snow, or reefs teeming with life. If ever something dark and dismal is presented it is us tearing down trees, melting the bears' home, or bleaching the reefs. We are the violence and we must stop it. 

However, in truth the natural world is a massive struggle for survival that takes no prisoners. Bears eat the seals that look so cute to us. Trees try to crowd out the light that would feed the children of their competitors. Insects go about parasitizing each other and many other creatures. It is a massive race to get before you're gotten. The harmony is not one of collective, atruistic cooperation but of struggle. 

Yet it is precisely this struggle that creates the very sustainability and stability that we depend upon and seek to emulate. Plants take up nutrients and energy which becomes food for hungry grazers who in turn become the prey of other creatures or disease and so it goes until all is returned to the earth where scavengers and eventually microorganisms return those nutrients back to the soil so that the process can start anew. The cycle of life and death is the cycle of renewal. 

Likewise stability is a result of these interplays, specifically in the form of negative feedback loops. Predators, food availability, and disease regulates the abundance of prey while the abundance of disease and prey availability regulates the abundance of predators. A gross over simplification to be sure, but it gets the point across - nature regulates itself through feedback. \newline

Nature then is not in harmony with itself because of some kind of stasis or inherent permanence but instead because hundreds of thousands of different dynamic elements are trying to gain ground and through their collective competition create the cycles that allow for sustainability and the negative feedback loops that allow for stability. Nature is the sustainability engine it is through its dynamic non-linearity. \newline

With this in mind I believe the place of management becomes clear. But let me illustrate with an example. Waste from human processes (better known today as pollution) has become a problem as of late. Run off enters our streams, estuaries, and oceans and has been known to create devastating blooms of algae that choke out the local life. What has happened here? Quite simply our interaction with the feedback loops present sent them cascading to a new "stable" point. When the waste showed up in the quantities it did microorganisms, who are known for their exceptional ability to multiply, were able to increase in quantity at rates that far exceeded any of their predators ability to compensate. The feedback loop could not keep pace. Eventually the mass of microorganisms got so large that they starved the area of much needed oxygen and their would be regulators died off instead.  

Consider instead what would have happened if that waste had more slowly leached into the system. If the rate was slow enough then these blooms would not have happened. It is not that the waste ended up there that is the immediate problem it is the fact that it came in so fast that it completely overwhelmed the feedback loop. 

We human beings \textit{will} produce waste and we \textit{will} consume resources from the earth. There is no such thing as a humanity separate from its biosphere. We are as much a part of the wild as anything else. The question to us is not whether we will engage with and shift the world by our presence (as compared to our absence) but rather whether the way we engineer our interactions results in \textit{dynamic} stability or not. Do we engineer interactions that mesh well with the feedback cycles out there or do we topple them over and race towards a great unknown? \newline 

\textit{Good management means engineering interactions with our dynamic, non-linear biosphere that take advantage of the cycles and feedback loops present to achieve dynamic stability and sustainability. Change is inevitable, instability is not.} \newline 


In order for us to be good managers then, we need to understand the feedback loops and cycles that are present. And this means looking at the world around us and asking - "what jobs do you do?" For example much of the issues that have arisen with industrial farming have come from not appreciating all the kinds of value the biosphere has been/was bringing us in the first place \cite{biomimicry}. Soil erosion, nitrogen fixing, pest mitigation, weather resistance, all of these are examples of "jobs" we've realized the biosphere has already figured out only after problems have cropped up from our having eliminated the species doing those jobs. Soil erosion is preventable if you have plants that can cover the ground and slow the water as it hits the earth as rain. Not as much nitrogen fertilizer is needed if nitrogen fixers are planted in fields as well whatever else is being grown there. Diversity in crops helps prevent plagues and just generally ensures not all of our eggs have been placed in one basket.

Likewise following the chain of feedback loops and "jobs" performed helps ensure we don't insert ourselves into an ecosystem attempting to achieve one kind of value while accidentally destroying another. Catching one kind of fish in great quantities that is prey for another valuable kind of fish can result in amping up one fishery while decimating another. Clearing predators in order to bump up hunting can eventually just result in poorer and poorer quality game as the predators are no longer around to put adaption pressure on the populations that are left. Removing wetlands in order to get more farmland and simply removing nurseries for valuable fish species. All in all it is important to recognize that not only are there many "jobs" being done but there are usually many values being derived from ecosystems simultaneously and unless we recognize these we are bound to erase things we depend upon by accident. \newline

\textit{Good management means understanding the full breadth of these systems, both in terms of all of the "jobs" performed to keep the system stable and sustainable, but also in terms of the various "jobs" performed that bring direct human value. That which goes unnoticed ends up being that which is eventually lost. }\newline

However this requirement for breadth presents us with a rather big problem. There are quite literally millions of different species distributed across our planet and that means there are an absolutely massive number of interactions, cycles, and feedback loops. Indeed this number gets even more severe if you think about the fact that each of these kinds of interactions play out in many different places at many different times across the globe. How can we possibly know all of this? Naively, if we were trying to describe each of these interactions and processes in hyper-specific detail we know, for a fact, that the task would be impossible - such knowledge would be more or less equivalent to omniscience. However we probably do not need such painfully precise detail. 

To illustrate, consider your car (or someone else's if you do not have one). Cars these days are extremely complicated. There are loads of different systems operating at all times when you are driving one. Pumps, engine(s), coolant systems, hydraulics, differentials, navigation systems, stereos, safety systems, lights... the list goes on and on. Yet you do not have to know all of these in all of their detail to drive the car around safely. Indeed driving a car is relatively easy. Building a car from scratch, however, takes the industry of many, many souls. The key is that you know what things you \textit{need} to pay attention to and what things you can leave as a black box. You know you need to steer with the steering wheel, use the gas and break pedals, indicate, and in certain more specific cases use the windshield wipers, understand that the oil light means its time to go to the mechanic, and so on. The operating abstraction of the car means that you needn't know how every last component in your car works to operate it. 

In a similar fashion we need an operating abstraction of ecosystems. We need to know what kinds of knowledge we need to get our hands on to operate responsibly, but also what information can be left a mystery so that the problem become tractable at all. We need to know how to break down stability and sustainability in a system to its basic, abstract parts. Thankfully such a field exists! Or rather, such fields exist and they are the fields of cybernetics, systems thinking/design, chaos theory, and stability theory. These four deal with how to understand and abstract non-linear systems and their dynamics. It will be (and to some extent already is) in applying and advancing these fields that a theory of ecological management arises. \newline

\textit{Good management takes advantage of the fields of cybernetics, systems thinking/design, chaos theory, and stability theory to provide operating abstractions of ecosystems that makes the problem of management tractable.}\newline

In sum then management is about taking the mathematical fields outlined above to produce an operating abstraction of ecological stability and sustainability, doing the research to describe the various "job" and values in the terms outlined by that operating abstraction, and then designing the human engagement in that system to achieve those values with dynamic stability and sustainability. Theory to knowledge to practice. \newline

Our next step then in understanding what it means to manage is to find that operating abstraction that will allow us to avoid the proverbial boiling of the ocean. 

\newpage



\section{Stability and Control}

What is a system? A system can be a lot of different things but fundamentally it is a set of states and how those states change. This allows us to define a pretty simple looking definition of a system. Suppose our state can be represented by a vector $x$. Following in the tradition of cybernetics\cite{cybernetics} we'll refer to this as our operand. Then our system simply transforms this operand into what we'll call a transform $x'$ which is just the new state of the system. The system therefore can be defined by $x'=T(x)$. Note here we're assuming that we're interested in our system as a set of discreet time steps. Also, for now we'll assume that $T$ is single valued which means that for each $x$ there is one and only one transform $x'$. Continuing in the language of cybernetics we call $T$ a transducer. So any system is simply a transducer. 

Let's define a simple example transducer for ourselves. Suppose our $x$ is a vector of the number of fish at ages 0, 1, 2, and so on. That is:

$$x=[n_0, n_1, ..., n_A]$$

where $A$ is the maximum age of the species in question.

Then suppose our transducer is given by:

$$n_i'=T_i(n_{i-1})=n_{i-1}M \forall i > 0$$

and 

$$n_0'=R$$

where $R > 0$ and $M < 1$.

This represents a system where each age group experiences the same mortality $M$ and we have constant recruitment of baby fish each year. A simple system indeed but one that will give us something more concrete to work with as we go along. \newline

Now our first question is - are there stable states within this system? What is a stable state? Well one situation that would be certainly stable is if there existed some $x$ such that $T(x)=x$ i.e. the system doesn't change the state. In our case this will be true if:

$$n_i=RM^i$$

This the represents an equilibrium point. We can however broaden this definition and ask whether there are sets of states $S=\{x\}$ such that for any $x\in S$ we also have that $T(x)\in S$. This would also be a kind of equilibrium in the sense that once the system enters $S$ it will never leave. Why broaden the definition like this? Well consider a system over three states $a$, $b$, and $c$ s.t. $T(a)=b$, $T(b)=a$ and $T(c)=a$. There is obviously no equilibrium point in this system as it will just volley back and forth between $a$ and $b$ but the set $S=\{a,b\}$ is still a smaller set than the whole domain of $T$ and clearly is stable within itself. In other words this definition allows us to still talk about stability even for oscillatory systems. 

A set $S$ is therefore considered \textbf{stable} if for all $x\in S$ it follows that $T(x)\in S$. If your system enters a stable set it will never leave that set. \newline

This however doesn't seem to really be enough to consider a system as a whole "stable". For example the transducer defined by $x'=T(x)=2x$ has a stable set $S=\{0\}$ but so long as $x\neq 0$ that system will never go to $S$. So what we want is not only a stable set $S$ but another set $U$ s.t. our system will tend towards $S$. 

One way we could define this would be to ask if there is a set $U$ s.t. the under operation of our transducer the system state gets closer to $S$ and the new state is also in $U$. Then, by induction we would be able to say that asymptotically states in $U$ would go to $S$. To put it more precisely we'd be looking for another stable region $U$ (because we need points in $U$ to lead to other points in $U$ under transformation by our system) such that $d(x, S) > d(T(x), S) \forall x \in U$. Were $d(x, S)$ is the distance between $x$ and $S$. 

Sometimes however $d$ is such a nasty function that evaluating that definition directly is quite difficult. When that is the case we can take advantage of an insight by Aleksandr Lyapunov\cite{stability}. Suppose that we have a function $V(x)$ defined on $U$ such that $V(x)=0$ when $x\in S$, $V(x)>0$ when $x\notin S$ and $V(x) > V(T(x)) \forall x\in U - S$. If these assumptions are true it also holds that the system tends toward $S$ while in $U$ and given $U$ is itself stable any point in $U$ \textit{will} asymptotically lead toward $S$. The $V$ are called Lyapunov Functions. 

So in general we can now say that if there exists a stable set $U$ over which a lyapunov function can be defined relative to another stable set $S$ that $S$ is an \textbf{attractor} which is asymptotically stable. \newline

So is our example system's equilibrium an attractor? Well if our equilibrium point is $s$, given some $x=[n_0, n_1, ..., n_A]$ we have:

$$x_i-s_i=n_i-RM^i$$

and 

$$T_i(x_i) - s_i = n_{i-1}M-RM^i \forall i>0$$
$$T_0(x_0) - s_0 = R - R = 0$$

Effectively then the difference for each element where $i>0$ is getting multiplied by $M$ and $n_0$ is getting set precisely to $R$. Therefore the distance from equilibrium is certainly dropping under $T$ and so our $s$ is indeed an attractor. \newline

At this point it seems our system is so simple it offers no interesting behavior. Surely if there were no fish to speak of we'd be in trouble! We can model this by creating a new piece-wise transducer where if the sum of $x$ is below some value $R$ begins to decrease with the sum of $x$. In other words if $\sum_i n_i < N$ then our $T_0$ becomes:

$$T_0=R  \frac{\sum_i n_i}{N}$$

In this case it will be noted we get a new stable set $x=0$. Our old stable set is also still there but now there is this "danger zone" as well. Indeed one can work out that there are sets $U$ and lyapunov functions for both of our equilibrium points that make both of them attractors. 

This is really important to highlight because it shows that a system does not just exhibit one kind of behavior. One can in general have multiple attractors and so understanding our system means dividing up its domain into regions of attraction to specific attractors and regions that are either unattracted or just simply diverge. \newline

Alright so far we've spoken of stable sets, attractors, and the fact that our system exhibits different behaviors based on the region it starts in. But we haven't yet talked about control. Control however is just the introduction of some new component to the system. I.e. rather than just having $T$ there is some second function $C$ which takes the output of $T$ and changes the states itself. However $C(T(x))=x'$ is itself just a new transducer. So everything we've talked about still applies. Where then is the control? Well usually $C$ will have "inputs". For example suppose that we've decided to apply a fishing mortality pressure $F$ to our earlier super simple system. I.e. we now have:

$$n_i'=T_i(n_{i-1})=n_{i-1}M \forall i > 0$$

and

$$n_0'=RF$$

Well we can see that as before we have an attractor now defined by:

$$n_i=RM^iF^{i+1}$$

The control here comes in the fact that we can \textit{choose} what $F$ should be. If $F$ is set to 0 then we arrive back at the old system, but as we vary $F$ the attractor will move. This is how we exert control. Note however that the set of attractors is simply a line through our state space. That is because we have a single control parameter. If we had two distinct parameters our set of equilibria would define a surface, if we had three a volume, and so on. I.e. the degrees of freedom in our control is limited by the degrees of freedom in our inputs. This is a restatement of the notion of Requisite Variety\cite{cybernetics}. Practically in our case it means that right now we can control how many fish we catch at equilibrium but not the age distribution of those fish. We'd need to add addition, independent control parameters to allow for that. \newline

Alright let's summarize what we now know:

\begin{enumerate}
\item \textbf{Transducers:} Any system (including ones with regulators) can be defined as a transducer.
\item \textbf{Stability:} A set $S$ is considered to be stable if for all $x\in S$ it is also true that $T(x)\in S$.
\item \textbf{Attractors:} A set $S$ is an attractor if there exists a stable set $U$ and a lyapunov function of $x\in U$ relative to set $S$. 
\item \textbf{Modes of Behavior:} In general a transducer $T$ may have multiple stable sets as well as regions that show no attraction. Therefore attraction is dependent both on the system and the starting state $x$. 
\item \textbf{Control:} Control comes from the inclusion of input parameters to the system. The result of control is the movement of attractors and their regions of attraction. 
\item \textbf{Requisite Variety:} The degrees of freedom in control is limited by the degrees of freedom in the input parameters. 
\item \textbf{Laissez-Faire:} Given the above it should be clear now that control in a deterministic system is not about constantly grappling with that system. Instead it is about designing a system with input parameters that give the degrees of freedom and movement in attractors that's desired. Then, once those parameters have been set there is nothing left to do but allow the system to follow its course to stability. 
\end{enumerate}

That last point should feel like it stands in stark contrast to reality. Certainly life is not so simple that you can just design systems and never worry about them again. Yet if $T$ can be trusted it seems like that is the case. But what happens if $T$ can't be trusted? What happens if it changes under our feet? Well that brings us directly to the question of systems with noise.  

\newpage


\section{Understanding Noise by Understanding Inputs}

Noise can be considered in a lot of different ways. However it seems practical to take a leaf out of the study of feedback control in linear time invariant systems \cite{feedback}. At first look these systems seem to be setup quite differently (from a mathematical) perspective than the ones we just went over in the last section. Specifically they are described by a series of ordinary differential equations that are concerned with an input function $u$, an output function $y$, and some parameter (usually time) $t$. One classic example is the dampened spring:

$$m\partial^2y+b\partial y+ky=u$$

This is no longer a direct definition of our transducer but instead a "constraint" governing what our transducer can look like. However given $u$ and the appropriate initial conditions this will give you a single $y(t)$ that describes the spring's path through state space. 

As such we can think of $y$ as a specific pathway, determined by $u$, and parametrized by $t$. What is $u$ then? Well it is a force applied to our spring over time and so we can consider it equivalent to setting the input on the transducer from one moment to the next - $u(t)$ is the output of an "input transducer" over time. What's important to notice here however is that $u$ is independent of $y$, i.e. $u$ is specified without knowing what $y$ is.\newline

How does this relate to noise? Well consider the fact that while a die is represented by some kind of distribution that in reality when the dice are rolled we get a specific set of dice rolls. Distributions exist to help us explain phenomena over many repeats of the same "experiment" but they don't really "exist" in real life - we are only ever left with one "pathway" through the state space that those distributions describe. So, if we had some gambling system where the "noise" was generated by dice rolls we can imagine that for any run of the experiment there is a specific $u$ that describes the rolls we got. This $u$ then feeds into our specific gambling system to then give us our path through the state space $y$. If we then want to consider what would happen under another set of dice rolls we'd construct a different $u$ and see what new $y$ we get out of it. But in each case our overall system of $u$ and $y$ stays deterministic and follows all the rules we illuminated in the last section. 

What we want to study then is how our system $y$ behaves under different input pathways $u$ and determine which $u$'s lead to bad outcomes. \newline

There is however a problem. In both this case and in the case of building lyupanov functions for the sake of studying stability there is no silver bullet, no single method (or at least no one has found one yet). A great quote from "Feedback Control of Dynamic Systems" is that "the theory only gives the engineer a hunting license to look for a [lyapunov] function" \cite{feedback}. So what are we to do? Well once again we can take a leaf out of the LTI (linear time invariant) systems book. \newline

Their way of dealing with this is to take advantage of the specific properties that make an LTI and LTI - and that's linearity and time invariance. This more or less means that if $u_1$ is one input with response $y_1$ and $u_2$ is an input with response $y_2$ that the response of $au_1 + bu_2$ (where $a$ and $b$ are constants) is given by $ay_1 + by_2$. In other words if a specific input can be represented as the sum of a series of inputs, its response is equal to the sum of the responses of the individual inputs. 

So what about the response to the dirac delta function? Suppose we call that $h(t)$. Then because the dirac delta function happens to be an impulse of size 1 that last only infinitesimally long that:

$$u(t) = \int_{-\infty}^{\infty}u(\tau) \delta(\tau)d\tau$$

and therefore:

$$y(t) = \int_{-\infty}^{\infty}u(\tau) h(t-\tau)d\tau$$

More or less all this is saying is that because our system in linear and time invariant that the response to some arbitrary input is the "sum" of the impulse responses multiplied by the magnitude of the input at that time carried forward (or backward) to the current time. 

This form in and of itself isn't so interesting but the magic happens when we consider what happens in our input is of the form $e^{st}$.

 $$y(t) = \int_{-\infty}^{\infty}e^{s\tau} h(t-\tau)d\tau$$
 
 which is equivalent under a change of variable to:
 
 $$y(t) = \int_{-\infty}^{\infty}e^{s(t-\tau)} h(\tau)d\tau = \int_{-\infty}^{\infty}e^{-s\tau} h(\tau)d\tau e^{st}=H(s)e^{-st}$$
 
 where $H(s)$ is the Laplace transform of $h(t)$. But notice that we've just shown that for an input $e^{st}$ our system will produce an output that is just some scalar multiple of the input! So what does this $H(s)$ look like? Well we can solve for it in our original equation:
 
 $$ms^2H(s)e^{st}+bsH(s)e^{st}+kH(s)e^{st}=e^{st}$$
 
 $$H(s) = \frac{1}{ms^2+bs+k}$$
 
This $H(s)$ (also known as the transfer function) tells us everything we need to know about how the systems responds to different frequencies of input $s$. For example if $s$ is a root of the above denominator we know we're going to have significant issues. And because we can imagine any arbitrary input $u$ as being some combinations of frequencies we've also sorted out how to tell what properties of the input could give us issues. Very useful indeed.\newline


Notice though that in order to arrive at this result we had to lean heavily on the system being LTI. For some other kind of system none of this would apply. And that's just the nature of studying systems - to find their specific properties there has to be some inherent structure (beyond just having a transducer of some kind) that you can leverage to pull out the characteristics of those systems. \newline

For us then it means that we need to find specific properties of ecosystem subsystems that will allow us to define them as a specific type(s) of system and then leverage those properties into understanding the characteristics of the inputs that could lead to issues. Only by getting specific are we going to be able to make any more progress. 

\newpage

\bibliographystyle{plain}
\bibliography{reference}
\end{document}