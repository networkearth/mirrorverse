# May 17, 2024

## Changeset

- Started the week by looking into the weird data discrepancies that I'd noted in the fishy email chain. Ended up determining that they are using some kind of binning when they aggregate which is why I was seeing those step shifts in the data. After quantifying the amount of error induced by doing that binning I realized that for each summary data point, the actually summary statistic that was binned might be within +-10% of the reported value. This in turns means that I have to treat each statistic as actually representative of a distribution rather than a measurement and in subsequent training I've been sampling from that distribution instead of taking the summary statistic itself as truth.
- I did mess around with fourier series a bit but due to both the fact that I'm dealing with summary data and this whole accuracy issue noted above I abandoned that pretty quickly as rather than having smooth oscillations like you see in the high resolution data I just have a lot of noisy step functions. So my fourier decompositions were just incredibly noisy and picking up no real patterns. [HTML to see specifics](https://github.com/networkearth/mirrorverse/blob/main/docs/studies/Cleanup_on_Aisle_9.html)
- So I went and looked at some other papers (this was before Michael referred some more to me) that have dealt with depth data and found that by and large they just bin the data into "depth" bins and then try to run statistics over those bins. Given the mangement application I have in mind here is bycatch avoidance this seemed like a reasonable way to move forward and would definitely help with smoothing out all the "noise". 
- Given the depth bins were easy to define and would always be present (unlike with my other behavioral models that had to deal with changing decision options) I gave a standard ML prediction approach a crack. And while I certainly could get some degree of prediction ([html to see specifics](https://github.com/networkearth/mirrorverse/blob/main/docs/studies/Depth_Classification.html)) I found that no matter what I did an implicit bias away from shallower water was always present. After some thought I realized this is necessarily the case with any standard predictive ML model - [Avoiding Inherent Bias](https://github.com/networkearth/mirrorverse/wiki/Odds-Modeling#avoiding-inherent-bias). Conclusion - I'd need to use odds modeling to prevent incorporating bias into the entire behavioral model. 
- This I started on towards the end of the week so I'm still working on this bit, but this data is a wonderful use case to allow me to really dig into this Odds Modeling approach. What's become incredibly clear as I've been working on this is that I need to get some more diagnostics for the actual convergence of the Odds function itself. But what's been cool is I can train the odds model with no features and get the distribution of fish per depth bin exactly as its found in the real data, then add features like month, or daytime/night and see that I ca still predict both overall probabilities and the distributions for each month or day vs night. So the modeling is definitely working, I just need to sort out some things to start taking in more features and deal with the "curse of dimensionality".

## Up Next

- Read the new papers.
- Add diagnostics for the convergence of the odds function.
- Deal with the fact that upon adding more features I've having trouble with out of sample prediction (curse of dimensionality).
- With those two done tie up the working odds model of depth that we can use as a baseline.


